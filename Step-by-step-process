Step1:

Fork the repository:

https://github.com/Sonal0409/Vodafone-DevOps-CapstoneProject.git

The above repository contains source code and test cases of a spring boot project
==========================================================================

Step 2: We will write github actions workflow YAML file to Build the code using Maven

Execute below  steps:

 > In the repository -> click on Actions Tab --> Choose a Workflow --> Setup and workflow yourself

 > A new Yaml file will open--> give name as ContinousIntegration.yml

 > Add the below YAML code


name: Capstone project CICD pipeline
on: 
 push:
jobs:
 capstoneproject:
 runs-on: ubuntu-latest
 steps:
  - name: Checkout the code
    uses: actions/checkout@v4
  - name: Install Java and Maven
    uses: actions/setup-java@v4
    with:
    distribution: 'temurin'
    java-version: '11'
    cache: maven
  - name: Build the code
    run: mvn package --file pom.xml

Step 3: We will now create a dockerfile and then build image using github actions. 
        We will also push the image to dockerhub using github Actions

Execute below  steps:

 > In the repository create a new file with name as Dockerfile

Add the below lines in the dockerfile and save the file


FROM tomcat:8
COPY target/java-example.war /usr/local/tomcat/webapps/ROOT.war
EXPOSE 8080
CMD ["catalina.sh", "run"]


Save the file

> As we have to push the image to dockerhub, we will create secrets in the repository to save dockerhub username and dockerhub password

> For this go to Settings tab of repository > go to secrets and variables > click on to Actions > Secrets Tab > Repository secrets > click on new repository secret

	> give name as DOCKERHUB_USERNAME ==> Secret as > your dockerhub username > Click on Add secret

	> Again  click on new repository secret > give name as DOCKERHUB_TOKEN > Secret as > your dockerhub password> click on add secret

	> Give the secret names in UPPERCASE, as we use the same secret name in the actions YAML file.


> In the repository > now go to .github/workflow folder --> you will find the main.yml file

> Click on Edit the file 

> Replace the content of the file with below content. 

name: Capstone project CICD pipeline
on: 
 push:
jobs:
 capstoneproject:
  runs-on: ubuntu-latest
  steps:
  - name: Checkout the code
    uses: actions/checkout@v4
  - name: Install Java and Maven
    uses: actions/setup-java@v4
    with:
     distribution: 'temurin'
     java-version: '11'
     cache: maven
  - name: Build the code
    run: mvn package --file pom.xml
  - name: Install docker
    uses: docker/setup-buildx-action@v3
  - name: Login to dockerhub
    uses: docker/login-action@v2
    with:
     username: ${{ secrets.DOCKERHUB_USERNAME }}
     password: ${{ secrets.DOCKERHUB_TOKEN }}
  - name: Build and Push the Image
    uses: docker/build-push-action@v4
    with:
     context: .
     push: true 
     tags: ${{ secrets.DOCKERHUB_USERNAME }}/capstoneimage:latest


Step 4: Create kubernetes Helm chart to deploy above image and push charts to github repo

> Connect to devOps lab > here we will install helm 

Execute below commands:
# sudo su -
# curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get-helm-3 > get_helm.sh
# chmod 700 get_helm.sh
# ./get_helm.sh

> clone your own github repo in which we have to push the charts

# git clone https://github.com/Sonal0409/Vodafone-DevOps-CapstoneProject.git
# ls
# cd Vodafone-DevOps-CapstoneProject

> Now we have to create a new Helm chart using which we are going to deploy our Custom Docker image. Follow below commands to create a new helm Chart

# helm create webapp
# ls -al webapp

> By default, you will get a lot of files inside this helm chart but we are going to delete those so that we donâ€™t see error while deploying these.

# cd webapp/
# pwd
# cd templates/
# ls -al
# rm -rf *.yaml NOTES.txt tests ../values.yaml 
# ls -la

Create Deployment and service YAMls

# vim deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
 name: capstone
spec:
 replicas: 3
 selector:
  matchLabels:
   app: capstone
 template:
  metadata:
   labels:
    app: capstone
  spec:
  containers:
   name: c1
   image: sonal04/capstoneimage

Save the file

# vim service.yaml

apiVersion: v1
kind: Service
metadata:
 name: mysvc
spec:
 type: NodePort
 ports:
  - targetPort: 8080
    port: 8080
 selector:
  app: capstone

Save the file

come out of templates and webapp folder

> cd ../..

> you will be in the repo folder

Execute git commands to commit the webapp folder and push to github

# git add .
# git commit -m "done helm"
# git push origin master
username: give you  personal access token
password: press enter key

[ to create personal acess token on github go to page  https://github.com/settings/tokens and create the token]

Step 5: Install terraform on the Lab

Goto lab and execute below steps:

wget -O - https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update && sudo apt install terraform


Step 6: Launch the AWS lab and create IAM user and accesskey and secret key

In AWS 

IAM > Users > click on add user > give a username > click next > select Attach policies directly > select AdministratorAccess below >> click on next > click on create user.

Now lets attach access key and secret key to the user.

Click on username>> click on security credentials > Select Access keys> click on create access key
 > sleect Command Line Interface (CLI)
> click on I understand the above recommendation and want to proceed to create an access key. > press next > click on create access key

===============================================

Step 7: go to terraform lab

# mkdir awsinfra
# cd awsinfra
# vim aws_infra.tf

variable "vpc_cidr" {
        default = "10.20.0.0/16"
}

variable "subnets_cidr" {
        default = "10.20.1.0/24"
}

variable "azs" {
        default = "us-east-1a"
}

provider "aws" {
      region = "us-east-1"  
      access_key = ""
      secret_key = ""
}

# VPC
resource "aws_vpc" "terra_vpc" {
  cidr_block       = var.vpc_cidr
  tags = {
    Name = "TerraVPC"
  }
}

# Internet Gateway
resource "aws_internet_gateway" "terra_igw" {
  vpc_id = aws_vpc.terra_vpc.id
  tags = {
    Name = "main"
  }
}

# Subnets : public
resource "aws_subnet" "public" {
  vpc_id = aws_vpc.terra_vpc.id
  cidr_block = var.subnets_cidr
  availability_zone = var.azs
  map_public_ip_on_launch = true
  tags = {
    Name = "Subnet"
  }
}

resource "aws_route_table" "public_rt" {
  vpc_id = aws_vpc.terra_vpc.id
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.terra_igw.id
  }
  tags = {
    Name = "publicRouteTable"
  }
}

# Route table association with public subnets
resource "aws_route_table_association" "a" {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public_rt.id
}


resource "aws_security_group" "my_security_group" {
  name = "mysg"
  description = "my security group."
  vpc_id = aws_vpc.terra_vpc.id
}

resource "aws_security_group_rule" "ssh_ingress_access" {
  type = "ingress"
  from_port = 22
  to_port = 22
  protocol = "tcp"
  cidr_blocks = [ "0.0.0.0/0" ] 
  security_group_id = "${aws_security_group.my_security_group.id}"
}

resource "aws_security_group_rule" "egress_access" {
  type = "egress"
  from_port = 0
  to_port = 65535
  protocol = "tcp"
  cidr_blocks = [ "0.0.0.0/0" ]
  security_group_id = "${aws_security_group.my_security_group.id}"
}

resource "aws_launch_configuration" "aws_autoscale_conf" {
  name          = "web_config"
  image_id      = "ami-0e1bed4f06a3b463d"
  instance_type = "t2.micro"
  security_groups =  [ "${aws_security_group.my_security_group.id}" ]
}


resource "aws_autoscaling_group" "mygroup" {
#  availability_zones        =  ["${var.azs}"]
  name                      = "autoscalegroup"
  max_size                  = 10
  min_size                  = 1
  health_check_grace_period = 30
  health_check_type         = "EC2"
 force_delete              = true
  vpc_zone_identifier       = ["${aws_subnet.public.id}"]
  termination_policies      = ["OldestInstance"]
  launch_configuration      = aws_launch_configuration.aws_autoscale_conf.name
}

Save the file

# terraform init

# terraform apply --auto-approve

==============================
Step 8: Connect to the AWS Instance that has been create dform the previous step

Now run the below command to install kubernetes on the aws instance

# sudo su -

## Install Containerd

sudo wget https://raw.githubusercontent.com/lerndevops/labs/master/scripts/installContainerd.sh -P /tmp
sudo bash /tmp/installContainerd.sh
sudo systemctl restart containerd.service


### Install kubeadm,kubelet,kubectl

sudo wget https://raw.githubusercontent.com/lerndevops/labs/master/scripts/installK8S.sh -P /tmp

sudo bash /tmp/installK8S.sh

## Initialize kubernetes Master Node

   # sudo kubeadm init --ignore-preflight-errors=all

Execute the below commands to setup kubectl and apiserver communication

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config


   ## install networking driver -- Weave/flannel/canal/calico etc...

   ## below installs calico networking driver

   kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml

   # Validate:  kubectl get nodes

# kubectl taint nodes --all node-role.kubernetes.io/control-plane-

> We also need to install Helm utility using below set of commands:


curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get-helm-3 > get_helm.sh
chmod 700 get_helm.sh
./get_helm.sh

> Now we have to enable root password and root user authentication to proceed with SSH connectivity from GitHub actions pipeline. 

sed -i 's|PasswordAuthentication no|PasswordAuthentication yes|g' /etc/ssh/sshd_config
sed -i 's|#PermitRootLogin prohibit-password|PermitRootLogin yes|g' /etc/ssh/sshd_config
service sshd restart
passwd root
ssh root@localhost "date"		(Enter Root user password configured by you in previous command)

=================================================================

name: Capstone project CICD pipeline
on: 
 push:
jobs:
 capstoneproject:
  runs-on: ubuntu-latest
  steps:
  - name: Checkout the code
    uses: actions/checkout@v4
  - name: Install Java and Maven
    uses: actions/setup-java@v4
    with:
     distribution: 'temurin'
     java-version: '11'
     cache: maven
  - name: Build the code
    run: mvn package --file pom.xml
  - name: Install docker
    uses: docker/setup-buildx-action@v3
  - name: Login to dockerhub
    uses: docker/login-action@v2
    with:
     username: ${{ secrets.DOCKERHUB_USERNAME }}
     password: ${{ secrets.DOCKERHUB_TOKEN }}
  - name: Build and Push the Image
    uses: docker/build-push-action@v4
    with:
     context: .
     push: true 
     tags: ${{ secrets.DOCKERHUB_USERNAME }}/capstoneimage:latest
  - name: Executing helm chart on Kubernetes Server Remotely
    uses: appleboy/ssh-action@v0.1.10
    with:
     host: 3.81.64.38
     username: root 
     password: root 
     port: 22 
     script: |
      git clone https://github.com/Sonal0409/Vodafone-DevOps-CapstoneProject.git
      cd Vodafone-DevOps-CapstoneProject
      helm list -A
      helm install mavenbuild-dev ./webapp
      helm list -A
      kubectl get all
